{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Espaço para deep learning ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>acral</th>\n",
       "      <th>back</th>\n",
       "      <th>chest</th>\n",
       "      <th>ear</th>\n",
       "      <th>...</th>\n",
       "      <th>genital</th>\n",
       "      <th>hand</th>\n",
       "      <th>lower extremity</th>\n",
       "      <th>neck</th>\n",
       "      <th>scalp</th>\n",
       "      <th>trunk</th>\n",
       "      <th>unknown</th>\n",
       "      <th>upper extremity</th>\n",
       "      <th>male</th>\n",
       "      <th>unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age  abdomen  acral  back  chest  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0        0      0     0      0   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0        0      0     0      0   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0        0      0     0      0   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0        0      0     0      0   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0        0      0     0      0   \n",
       "\n",
       "   ear   ...     genital  hand  lower extremity  neck  scalp  trunk  unknown  \\\n",
       "0    0   ...           0     0                0     0      1      0        0   \n",
       "1    0   ...           0     0                0     0      1      0        0   \n",
       "2    0   ...           0     0                0     0      1      0        0   \n",
       "3    0   ...           0     0                0     0      1      0        0   \n",
       "4    1   ...           0     0                0     0      0      0        0   \n",
       "\n",
       "   upper extremity  male  unknown  \n",
       "0                0     1        0  \n",
       "1                0     1        0  \n",
       "2                0     1        0  \n",
       "3                0     1        0  \n",
       "4                0     1        0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('HAM10000_metadata.csv')\n",
    "\n",
    "#Categorização do atributo 'localization'\n",
    "data_localization = pd.get_dummies(dataset.localization)\n",
    "dataset = pd.concat([dataset, data_localization], axis=1)\n",
    "\n",
    "#Categorização do atributo 'sex'\n",
    "data_sex = pd.get_dummies(dataset.sex)\n",
    "dataset = pd.concat([dataset, data_sex], axis=1)\n",
    "\n",
    "dataset = dataset.drop(['sex', 'localization', 'female'], axis = 1)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regra da Pirâmide Geométrica\n",
    "\n",
    "Implementação da Regra da Pirâmide Geométrica para determinação da quantidade de Neurônios Ocultos\n",
    "\n",
    "        Nh = α·√(Ni·No) ; Nh = Número de Neurônios Ocultos\n",
    "                          Ni = Número de Neurônios de Entrada\n",
    "                          No = Número de Neurônios de Saída\n",
    "                          α  = Constante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piramide_geometrica(ni, no, alfa):\n",
    "    nh = alfa*((ni*no)**(1/2))\n",
    "    return ceil(nh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Distribuição dos Neurônios em duas Camadas Ocultas\n",
    "\n",
    "Função para gerar todas as possíveis 2-tuplas que representam o número de neurônios distribuídos por duas camadas ocultas de uma RNA do tipo MLP, dado o número de neurônios ocultos obtidos previamente pela Regra da Pirâmide Geométrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_layers(layers, nh):\n",
    "    for i in range(1, nh):\n",
    "        neurons_layers = (i, nh-i)\n",
    "        layers.append(neurons_layers)\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação de Lista de Camadas Ocultas a Partir da Regra da Pirâmide Geométrica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_in = ?\n",
    "num_out = 7\n",
    "alpha = [0.5, 1, 2, 3]\n",
    "layers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para α = 0.5, Nh = 4\n",
      "Para α = 1.0, Nh = 7\n",
      "Para α = 2.0, Nh = 14\n",
      "Para α = 3.0, Nh = 21\n",
      "\n",
      "Distribuições de Camadas Ocultas:\n",
      "\n",
      "(1, 3)\n",
      "(2, 2)\n",
      "(3, 1)\n",
      "(1, 6)\n",
      "(2, 5)\n",
      "(3, 4)\n",
      "(4, 3)\n",
      "(5, 2)\n",
      "(6, 1)\n",
      "(1, 13)\n",
      "(2, 12)\n",
      "(3, 11)\n",
      "(4, 10)\n",
      "(5, 9)\n",
      "(6, 8)\n",
      "(7, 7)\n",
      "(8, 6)\n",
      "(9, 5)\n",
      "(10, 4)\n",
      "(11, 3)\n",
      "(12, 2)\n",
      "(13, 1)\n",
      "(1, 20)\n",
      "(2, 19)\n",
      "(3, 18)\n",
      "(4, 17)\n",
      "(5, 16)\n",
      "(6, 15)\n",
      "(7, 14)\n",
      "(8, 13)\n",
      "(9, 12)\n",
      "(10, 11)\n",
      "(11, 10)\n",
      "(12, 9)\n",
      "(13, 8)\n",
      "(14, 7)\n",
      "(15, 6)\n",
      "(16, 5)\n",
      "(17, 4)\n",
      "(18, 3)\n",
      "(19, 2)\n",
      "(20, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(alpha)):\n",
    "    nh = piramide_geometrica(num_in, num_out, alpha[i])\n",
    "    print('Para α = %.1f, Nh = %d'%(alpha[i],nh))\n",
    "    hidden_layers(layers, nh)#insere cada possibilidade de camadas ocultas, dado o numero de neurônios, na lista 'layers'\n",
    "    \n",
    "print()\n",
    "print('Distribuições de Camadas Ocultas:\\n')\n",
    "for i in layers:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busca em Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'solver': ['lbfgs', 'adam', 'sgd'], \n",
    "              'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "              'hidden_layer_sizes': layers,\n",
    "              'max_iter':[1000, 2000, 5000],\n",
    "              'learning_rate_init':[0.005, 0.0005, 0.0001],\n",
    "              'learning_rate': ['adaptive', 'constant']}\n",
    "\n",
    "gs = GridSearchCV(MLPClassifier(), \n",
    "                  parameters, \n",
    "                  cv=3, \n",
    "                  scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.drop(['dx', 'lesion_id', 'image_id', 'dx_type'], axis = 1) #Atributos preditores\n",
    "y = dataset.dx #Atributo Alvo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento \n",
    "\n",
    "Treinamento de todas as combinações de RNAs definidas no GridSearchCV( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acurácia e Parâmetros do melhor modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acurácia para o conjunto de testes\n",
    "print('Acurácia média para os 3 splits de teste do melhor modelo:',gs.best_score_)\n",
    "\n",
    "print('\\nParâmetros:')\n",
    "for key in gs.best_params_.keys():\n",
    "    print('\\t',key, ': ', gs.best_params_[key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
